# LLMZoomcamp

Deploying LLM and RAGs in production


Looking forward, the future of generative AI lies in creatively chaining all sorts of LLMs and knowledge bases together to create new kinds of assistants that deliver authoritative results users can verify.

## Week 0 - Build a Q&A system for course-related FAQ documents

The LLM RAG Workshop covered the integration of Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG). It includes setting up the environment, running ElasticSearch for document indexing and retrieval, and generating answers using OpenAI. The extended workshop features using Ollama, Docker-Compose, Streamlit for web interfaces, and open-source models from HuggingFace. The practical goal is to build a Q&A system for Zoomcamp FAQ documents, enhancing the understanding and application of LLM and RAG technologies.
